{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a57a91af-e283-4134-b01a-16122c582108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in current directory:\n",
      "['.ipynb_checkpoints', '.ipython', '.jupyter', '.matplotlib', '.ms-ad', '.vscode', '3D Objects', 'age.csv', 'AppData', 'Application Data', 'BigData.ipynb', 'clean_data_after_eda.csv', 'client_data (1).csv', 'Contacts', 'Cookies', 'data_for_predictions.csv', 'Desktop', 'Documents', 'Downloads', 'engineered_data.csv', 'Favorites', 'h.txt', 'heart.csv', 'heart_correlation_matrix.csv', 'heart_covariance_matrix.csc', 'heart_variance.csv', 'height-weight.csv', 'IntelGraphicsProfiles', 'iris_correlation.csv', 'iris_correlation_matrix.csv', 'iris_corvariance.csv', 'iris_covariance.csv', 'iris_covariance_matrix.csc', 'iris_variance.csv', 'Links', 'Local Settings', 'Microsoft', 'Music', 'My Documents', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TM.blf', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{53b39e88-18c4-11ea-a811-000d3aa4692b}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'PDFEditor', 'Pictures', 'Powerco_eda_analysis.ipynb', 'Powerco_feature_engineering..ipynb', 'powerco_task2_EDA.ipynb', 'price_data (1).csv', 'PrintHood', 'Recent', 'Saved Games', 'Searches', 'SendTo', 'Start Menu', 'Templates', 'Untitled.ipynb', 'Untitled1.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Videos']\n",
      "\n",
      "Model Evaluation Metrics:\n",
      "Accuracy  : 0.8990\n",
      "Precision : 0.7083\n",
      "Recall    : 0.0557\n",
      "F1 Score  : 0.1033\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n- Accuracy: Measures overall correct predictions.\\n- Precision: Important if we want to reduce false positives (predicting churn when they won't).\\n- Recall: Important if we want to catch as many churners as possible.\\n- F1 Score: A balanced measure of Precision and Recall, ideal when classes are imbalanced.\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üìå Import Required Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# üìÇ Step 1: Check Current Directory for Data File\n",
    "print(\"Files in current directory:\")\n",
    "print(os.listdir())\n",
    "\n",
    "# üì• Step 2: Load the Final Dataset\n",
    "df = pd.read_csv(\"data_for_predictions.csv\")\n",
    "\n",
    "# üßπ Step 3: Drop Irrelevant Columns\n",
    "# ID column is typically unique to each row and not useful for prediction\n",
    "if 'id' in df.columns:\n",
    "    df = df.drop('id', axis=1)\n",
    "\n",
    "# üéØ Step 4: Split Features and Target\n",
    "X = df.drop(\"churn\", axis=1)  # Features\n",
    "y = df[\"churn\"]               # Target label\n",
    "\n",
    "# üîÑ Step 5: Encode Categorical Variables (if any)\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# ‚úÇÔ∏è Step 6: Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# üå≤ Step 7: Train Random Forest Classifier\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# üîç Step 8: Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# üìä Step 9: Evaluate Model Performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "# üßæ Step 10: Print Evaluation Metrics\n",
    "print(\"\\nModel Evaluation Metrics:\")\n",
    "print(f\"Accuracy  : {accuracy:.4f}\")\n",
    "print(f\"Precision : {precision:.4f}\")\n",
    "print(f\"Recall    : {recall:.4f}\")\n",
    "print(f\"F1 Score  : {f1:.4f}\")\n",
    "\n",
    "# üß† Metric Justification (add this in a Markdown cell if using Jupyter Notebook):\n",
    "\"\"\"\n",
    "- Accuracy: Measures overall correct predictions.\n",
    "- Precision: Important if we want to reduce false positives (predicting churn when they won't).\n",
    "- Recall: Important if we want to catch as many churners as possible.\n",
    "- F1 Score: A balanced measure of Precision and Recall, ideal when classes are imbalanced.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cffc26-8357-4be0-9c18-bfdaf05831d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
